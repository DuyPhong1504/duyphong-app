-- H2 Data for DuyPhong App
-- Sample data converted from MySQL dump

-- Insert departments
INSERT INTO departments VALUES 
('1dacf20a-4134-49fb-96b4-4e856f7b7e5f','first test department'),
('dept-001','Sales'),
('dept-002','Marketing'),
('dept-003','Human Resources'),
('dept-004','Finance'),
('dept-005','Engineering'),
('dept-006','Research and Development'),
('dept-007','Customer Support'),
('dept-008','IT Services'),
('dept-009','Legal'),
('dept-010','Product Management'),
('dept-011','Operations'),
('dept-012','Public Relations'),
('dept-013','Logistics'),
('dept-014','Quality Assurance'),
('dept-015','Training and Development'),
('dept-016','Strategy'),
('dept-017','Business Development'),
('dept-018','Design'),
('dept-019','Analytics'),
('dept-020','Field Operations');

-- Insert employees (sample data - first 20 employees)
INSERT INTO employees VALUES 
('emp-001','j.doe','john.doe@example.com','Nguyen Duy Phong','dept-005','Software Developer',26000000,'2023-01-15 09:00:00','2025-09-16 15:17:38'),
('emp-002','a.smith','jane.smith@example.com','Jane Smith','dept-002','Marketing Specialist',65000,'2023-02-20 10:30:00','2023-02-20 10:30:00'),
('emp-003','m.garcia','mike.garcia@example.com','Mike Garcia','dept-005','Software Engineer',95000,'2023-03-10 11:45:00','2023-03-10 11:45:00'),
('emp-004','e.jones','emily.jones@example.com','Emily Jones','dept-004','Financial Analyst',70000,'2023-04-05 14:00:00','2023-04-05 14:00:00'),
('emp-005','b.williams','bryan.williams@example.com','Bryan Williams','dept-003','HR Generalist',60000,'2023-05-01 09:30:00','2023-05-01 09:30:00'),
('emp-006','s.brown','sara.brown@example.com','Sara Brown','dept-005','Data Scientist',110000,'2023-05-15 13:00:00','2023-05-15 13:00:00'),
('emp-007','j.miller','jack.miller@example.com','Jack Miller','dept-006','Research Scientist',120000,'2023-06-25 15:00:00','2023-06-25 15:00:00'),
('emp-008','l.wilson','linda.wilson@example.com','Linda Wilson','dept-007','Customer Support Agent',55000,'2023-07-01 08:45:00','2023-07-01 08:45:00'),
('emp-009','c.moore','chris.moore@example.com','Chris Moore','dept-008','Network Administrator',85000,'2023-07-10 10:15:00','2023-07-10 10:15:00'),
('emp-010','n.taylor','nancy.taylor@example.com','Nancy Taylor','dept-009','Legal Counsel',130000,'2023-08-01 11:00:00','2023-08-01 11:00:00'),
('emp-011','d.anderson','david.anderson@example.com','David Anderson','dept-010','Product Manager',105000,'2023-08-20 14:30:00','2023-08-20 14:30:00'),
('emp-012','p.thomas','patricia.thomas@example.com','Patricia Thomas','dept-011','Operations Manager',90000,'2023-09-01 09:00:00','2023-09-01 09:00:00'),
('emp-013','r.jackson','robert.jackson@example.com','Robert Jackson','dept-012','PR Coordinator',68000,'2023-09-15 10:45:00','2023-09-15 10:45:00'),
('emp-014','m.white','mary.white@example.com','Mary White','dept-013','Logistics Coordinator',58000,'2023-10-01 11:30:00','2023-10-01 11:30:00'),
('emp-015','j.harris','james.harris@example.com','James Harris','dept-014','QA Engineer',75000,'2023-10-10 15:00:00','2023-10-10 15:00:00'),
('emp-016','a.clark','anna.clark@example.com','Anna Clark','dept-015','Training Specialist',62000,'2023-10-25 09:00:00','2023-10-25 09:00:00'),
('emp-017','l.lewis','lisa.lewis@example.com','Lisa Lewis','dept-016','Strategic Planner',115000,'2023-11-01 10:00:00','2023-11-01 10:00:00'),
('emp-018','p.walker','paul.walker@example.com','Paul Walker','dept-017','Business Development Manager',100000,'2023-11-15 13:00:00','2023-11-15 13:00:00'),
('emp-019','e.hall','elizabeth.hall@example.com','Elizabeth Hall','dept-018','UX/UI Designer',88000,'2023-12-01 14:30:00','2023-12-01 14:30:00'),
('emp-020','j.allen','joseph.allen@example.com','Joseph Allen','dept-019','Data Analyst',72000,'2023-12-10 16:00:00','2023-12-10 16:00:00');

-- Insert department history (sample data - first 20 records)
INSERT INTO department_history VALUES 
(1,'emp-001',NULL,'dept-001','2023-01-15 09:00:00'),
(2,'emp-002',NULL,'dept-002','2023-02-20 10:30:00'),
(3,'emp-003',NULL,'dept-005','2023-03-10 11:45:00'),
(4,'emp-004',NULL,'dept-004','2023-04-05 14:00:00'),
(5,'emp-005',NULL,'dept-003','2023-05-01 09:30:00'),
(6,'emp-006',NULL,'dept-005','2023-05-15 13:00:00'),
(7,'emp-007',NULL,'dept-006','2023-06-25 15:00:00'),
(8,'emp-008',NULL,'dept-007','2023-07-01 08:45:00'),
(9,'emp-009',NULL,'dept-008','2023-07-10 10:15:00'),
(10,'emp-010',NULL,'dept-009','2023-08-01 11:00:00'),
(11,'emp-011',NULL,'dept-010','2023-08-20 14:30:00'),
(12,'emp-012',NULL,'dept-011','2023-09-01 09:00:00'),
(13,'emp-013',NULL,'dept-012','2023-09-15 10:45:00'),
(14,'emp-014',NULL,'dept-013','2023-10-01 11:30:00'),
(15,'emp-015',NULL,'dept-014','2023-10-10 15:00:00'),
(16,'emp-016',NULL,'dept-015','2023-10-25 09:00:00'),
(17,'emp-017',NULL,'dept-016','2023-11-01 10:00:00'),
(18,'emp-018',NULL,'dept-017','2023-11-15 13:00:00'),
(19,'emp-019',NULL,'dept-018','2023-12-01 14:30:00'),
(20,'emp-020',NULL,'dept-019','2023-12-10 16:00:00'),
(21,'emp-001','dept-001','dept-005','2025-09-16 15:17:38');

-- Insert tasks (sample data - first 20 tasks)
INSERT INTO tasks VALUES 
(1,'emp-001','Q1 Sales Report','Complete the Q1 sales performance analysis and report.','2023-03-31','COMPLETED','2025-09-16 12:20:26','2025-09-16 12:20:26'),
(2,'emp-002','Marketing Campaign Launch','Launch the new product marketing campaign on social media platforms.','2023-04-15','IN_PROGRESS','2025-09-16 12:20:26','2025-09-16 12:20:26'),
(3,'emp-003','Backend Service Refactoring','Refactor the user authentication service for better performance.','2023-05-01','TO_DO','2025-09-16 12:20:26','2025-09-16 12:20:26'),
(4,'emp-004','Budget Review','Review and finalize the department budget for the next quarter.','2023-04-20','COMPLETED','2025-09-16 12:20:26','2025-09-16 12:20:26'),
(5,'emp-005','Onboarding New Hires','Prepare and conduct the onboarding session for 5 new employees.','2023-05-10','COMPLETED','2025-09-16 12:20:26','2025-09-16 12:20:26'),
(6,'emp-006','Data Model Optimization','Optimize the database schema for the new analytics feature.','2023-06-01','IN_PROGRESS','2025-09-16 12:20:26','2025-09-16 12:20:26'),
(7,'emp-007','Research New AI Algorithm','Conduct research on the latest AI algorithms for natural language processing.','2023-08-30','IN_PROGRESS','2025-09-16 12:20:26','2025-09-16 12:20:26'),
(8,'emp-008','Customer Support Training Manual','Create a new training manual for customer support agents.','2023-07-20','COMPLETED','2025-09-16 12:20:26','2025-09-16 12:20:26'),
(9,'emp-009','Server Migration','Migrate the legacy server to a new cloud-based infrastructure.','2023-08-15','TO_DO','2025-09-16 12:20:26','2025-09-16 12:20:26'),
(10,'emp-010','Contract Review','Review and approve the new vendor contracts.','2023-08-25','COMPLETED','2025-09-16 12:20:26','2025-09-16 12:20:26'),
(11,'emp-011','Product Roadmap Planning','Plan the product roadmap for the next 6 months based on user feedback.','2023-09-30','IN_PROGRESS','2025-09-16 12:20:26','2025-09-16 12:20:26'),
(12,'emp-012','Logistics Optimization','Analyze and optimize the supply chain logistics process.','2023-10-10','IN_PROGRESS','2025-09-16 12:20:26','2025-09-16 12:20:26'),
(13,'emp-013','Press Release Draft','Draft a press release for the upcoming product launch event.','2023-10-05','COMPLETED','2025-09-16 12:20:26','2025-09-16 12:20:26'),
(14,'emp-014','Inventory Audit','Perform a full audit of the warehouse inventory.','2023-10-25','IN_PROGRESS','2025-09-16 12:20:26','2025-09-16 12:20:26'),
(15,'emp-015','Automated Test Suite','Develop and implement an automated test suite for the web application.','2023-11-15','TO_DO','2025-09-16 12:20:26','2025-09-16 12:20:26'),
(16,'emp-016','Leadership Training Module','Develop a new training module for aspiring team leaders.','2023-11-20','COMPLETED','2025-09-16 12:20:26','2025-09-16 12:20:26'),
(17,'emp-017','Market Entry Strategy','Develop a strategic plan for entering a new international market.','2023-12-01','IN_PROGRESS','2025-09-16 12:20:26','2025-09-16 12:20:26'),
(18,'emp-018','Client Acquisition','Identify and contact potential new clients for business development.','2023-12-10','IN_PROGRESS','2025-09-16 12:20:26','2025-09-16 12:20:26'),
(19,'emp-019','User Flow Analysis','Analyze user behavior and identify pain points in the current application flow.','2023-12-30','COMPLETED','2025-09-16 12:20:26','2025-09-16 12:20:26'),
(20,'emp-020','Quarterly Data Analysis','Analyze quarterly sales and marketing data to find trends.','2024-01-10','COMPLETED','2025-09-16 12:20:26','2025-09-16 12:20:26');

-- Insert lunch logs (sample data - first 20 records)
INSERT INTO lunch_logs VALUES 
(1,'emp-001','2023-01-16','Lunch','The Burger Joint','Team lunch with sales department.'),
(2,'emp-002','2023-02-21','Lunch','Pasta Paradise','Lunch with new marketing hires.'),
(3,'emp-003','2023-03-11','Lunch','Taco Fiesta','Lunch with the dev team.'),
(4,'emp-004','2023-04-06','Lunch','Healthy Bowl','Grabbed a quick salad.'),
(5,'emp-005','2023-05-02','Lunch','BBQ Pit','Celebratory lunch for new project start.'),
(6,'emp-006','2023-05-16','Lunch','Sushi Express','Quick sushi lunch.'),
(7,'emp-007','2023-06-26','Lunch','Pizza Palace','Lunch with the research team.'),
(8,'emp-008','2023-07-02','Lunch','Subway','Grab and go lunch.'),
(9,'emp-009','2023-07-11','Lunch','Noodle House','Lunch with IT team.'),
(10,'emp-010','2023-08-02','Lunch','Steakhouse','Lunch with legal team.'),
(11,'emp-011','2023-08-21','Lunch','Coffee Shop','Quick sandwich lunch.'),
(12,'emp-012','2023-09-02','Lunch','Deli','Lunch at the office.'),
(13,'emp-013','2023-09-16','Lunch','Chinese Buffet','Lunch with PR team.'),
(14,'emp-014','2023-10-02','Lunch','Mexican Grill','Lunch with logistics team.'),
(15,'emp-015','2023-10-11','Lunch','Sushi Bar','Lunch with QA team.'),
(16,'emp-016','2023-10-26','Lunch','Indian Cuisine','Lunch with training team.'),
(17,'emp-017','2023-11-02','Lunch','Thai Restaurant','Lunch with strategy team.'),
(18,'emp-018','2023-11-16','Lunch','Italian Cafe','Lunch with new business development team.'),
(19,'emp-019','2023-12-02','Lunch','Sandwich Shop','Grabbed a quick sandwich.'),
(20,'emp-020','2023-12-11','Lunch','Korean BBQ','Lunch with data analytics team.');